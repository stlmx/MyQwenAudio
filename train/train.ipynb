{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments, HfArgumentParser\n",
    "\n",
    "ENDOFTEXT = \"<|endoftext|>\"\n",
    "IMSTART = \"<|im_start|>\"\n",
    "IMEND = \"<|im_end|>\"\n",
    "IGNORE_TOKEN_ID = -100\n",
    "\n",
    "global RANK\n",
    "\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    model_name_or_path: str = field(default=\"Qwen/Qwen-7B\")\n",
    "\n",
    "@dataclass\n",
    "class TrainingArguments(TrainingArguments):\n",
    "    use_lora : bool = field(default=False)\n",
    "\n",
    "@dataclass\n",
    "class DataArguments:\n",
    "    data_path : str = field(default=\"/root/codes/MyQwenAudio/data/emov_db/qa_data.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'audio': '/root/autodl-tmp/audio_data/neutral_337-364_0359.wav',\n",
       "  'content': '说话者在音频中提到了什么？'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Earth and gravel seemed to fill the pan. 锅里似乎装满了泥土和沙砾。'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {\"messages\": [{\"role\": \"user\", \"audio\": \"/root/autodl-tmp/audio_data/neutral_337-364_0359.wav\", \"content\": \"说话者在音频中提到了什么？\"}, {\"role\": \"assistant\", \"content\": \"Earth and gravel seemed to fill the pan. 锅里似乎装满了泥土和沙砾。\"}]}\n",
    "a['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(args):\n",
    "    model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=args.model_name_or_path, trust_remote_code=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=args.model_name_or_path, padding_side='right', trust_remote_code=True)\n",
    "\n",
    "    tokenizer.pad_token_id = tokenizer.eod_id\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    model_name_or_path = \"/root/autodl-tmp/hf_home/Qwen-Audio\"\n",
    "\n",
    "myargs= args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d1ff9f5c6b41bfbca4d2721642130b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /root/autodl-tmp/hf_home/Qwen-Audio were not used when initializing QWenLMHeadModel: ['transformer.audio.blocks.1.attn.key.weight', 'transformer.audio.blocks.1.attn.out.bias', 'transformer.audio.blocks.1.attn.out.weight', 'transformer.audio.blocks.1.attn.query.bias', 'transformer.audio.blocks.1.attn.query.weight', 'transformer.audio.blocks.1.attn.value.bias', 'transformer.audio.blocks.1.attn.value.weight', 'transformer.audio.blocks.1.attn_ln.bias', 'transformer.audio.blocks.1.attn_ln.weight', 'transformer.audio.blocks.1.mlp.0.bias', 'transformer.audio.blocks.1.mlp.0.weight', 'transformer.audio.blocks.1.mlp.2.bias', 'transformer.audio.blocks.1.mlp.2.weight', 'transformer.audio.blocks.1.mlp_ln.bias', 'transformer.audio.blocks.1.mlp_ln.weight', 'transformer.audio.blocks.10.attn.key.weight', 'transformer.audio.blocks.10.attn.out.bias', 'transformer.audio.blocks.10.attn.out.weight', 'transformer.audio.blocks.10.attn.query.bias', 'transformer.audio.blocks.10.attn.query.weight', 'transformer.audio.blocks.10.attn.value.bias', 'transformer.audio.blocks.10.attn.value.weight', 'transformer.audio.blocks.10.attn_ln.bias', 'transformer.audio.blocks.10.attn_ln.weight', 'transformer.audio.blocks.10.mlp.0.bias', 'transformer.audio.blocks.10.mlp.0.weight', 'transformer.audio.blocks.10.mlp.2.bias', 'transformer.audio.blocks.10.mlp.2.weight', 'transformer.audio.blocks.10.mlp_ln.bias', 'transformer.audio.blocks.10.mlp_ln.weight', 'transformer.audio.blocks.11.attn.key.weight', 'transformer.audio.blocks.11.attn.out.bias', 'transformer.audio.blocks.11.attn.out.weight', 'transformer.audio.blocks.11.attn.query.bias', 'transformer.audio.blocks.11.attn.query.weight', 'transformer.audio.blocks.11.attn.value.bias', 'transformer.audio.blocks.11.attn.value.weight', 'transformer.audio.blocks.11.attn_ln.bias', 'transformer.audio.blocks.11.attn_ln.weight', 'transformer.audio.blocks.11.mlp.0.bias', 'transformer.audio.blocks.11.mlp.0.weight', 'transformer.audio.blocks.11.mlp.2.bias', 'transformer.audio.blocks.11.mlp.2.weight', 'transformer.audio.blocks.11.mlp_ln.bias', 'transformer.audio.blocks.11.mlp_ln.weight', 'transformer.audio.blocks.12.attn.key.weight', 'transformer.audio.blocks.12.attn.out.bias', 'transformer.audio.blocks.12.attn.out.weight', 'transformer.audio.blocks.12.attn.query.bias', 'transformer.audio.blocks.12.attn.query.weight', 'transformer.audio.blocks.12.attn.value.bias', 'transformer.audio.blocks.12.attn.value.weight', 'transformer.audio.blocks.12.attn_ln.bias', 'transformer.audio.blocks.12.attn_ln.weight', 'transformer.audio.blocks.12.mlp.0.bias', 'transformer.audio.blocks.12.mlp.0.weight', 'transformer.audio.blocks.12.mlp.2.bias', 'transformer.audio.blocks.12.mlp.2.weight', 'transformer.audio.blocks.12.mlp_ln.bias', 'transformer.audio.blocks.12.mlp_ln.weight', 'transformer.audio.blocks.13.attn.key.weight', 'transformer.audio.blocks.13.attn.out.bias', 'transformer.audio.blocks.13.attn.out.weight', 'transformer.audio.blocks.13.attn.query.bias', 'transformer.audio.blocks.13.attn.query.weight', 'transformer.audio.blocks.13.attn.value.bias', 'transformer.audio.blocks.13.attn.value.weight', 'transformer.audio.blocks.13.attn_ln.bias', 'transformer.audio.blocks.13.attn_ln.weight', 'transformer.audio.blocks.13.mlp.0.bias', 'transformer.audio.blocks.13.mlp.0.weight', 'transformer.audio.blocks.13.mlp.2.bias', 'transformer.audio.blocks.13.mlp.2.weight', 'transformer.audio.blocks.13.mlp_ln.bias', 'transformer.audio.blocks.13.mlp_ln.weight', 'transformer.audio.blocks.14.attn.key.weight', 'transformer.audio.blocks.14.attn.out.bias', 'transformer.audio.blocks.14.attn.out.weight', 'transformer.audio.blocks.14.attn.query.bias', 'transformer.audio.blocks.14.attn.query.weight', 'transformer.audio.blocks.14.attn.value.bias', 'transformer.audio.blocks.14.attn.value.weight', 'transformer.audio.blocks.14.attn_ln.bias', 'transformer.audio.blocks.14.attn_ln.weight', 'transformer.audio.blocks.14.mlp.0.bias', 'transformer.audio.blocks.14.mlp.0.weight', 'transformer.audio.blocks.14.mlp.2.bias', 'transformer.audio.blocks.14.mlp.2.weight', 'transformer.audio.blocks.14.mlp_ln.bias', 'transformer.audio.blocks.14.mlp_ln.weight', 'transformer.audio.blocks.15.attn.key.weight', 'transformer.audio.blocks.15.attn.out.bias', 'transformer.audio.blocks.15.attn.out.weight', 'transformer.audio.blocks.15.attn.query.bias', 'transformer.audio.blocks.15.attn.query.weight', 'transformer.audio.blocks.15.attn.value.bias', 'transformer.audio.blocks.15.attn.value.weight', 'transformer.audio.blocks.15.attn_ln.bias', 'transformer.audio.blocks.15.attn_ln.weight', 'transformer.audio.blocks.15.mlp.0.bias', 'transformer.audio.blocks.15.mlp.0.weight', 'transformer.audio.blocks.15.mlp.2.bias', 'transformer.audio.blocks.15.mlp.2.weight', 'transformer.audio.blocks.15.mlp_ln.bias', 'transformer.audio.blocks.15.mlp_ln.weight', 'transformer.audio.blocks.16.attn.key.weight', 'transformer.audio.blocks.16.attn.out.bias', 'transformer.audio.blocks.16.attn.out.weight', 'transformer.audio.blocks.16.attn.query.bias', 'transformer.audio.blocks.16.attn.query.weight', 'transformer.audio.blocks.16.attn.value.bias', 'transformer.audio.blocks.16.attn.value.weight', 'transformer.audio.blocks.16.attn_ln.bias', 'transformer.audio.blocks.16.attn_ln.weight', 'transformer.audio.blocks.16.mlp.0.bias', 'transformer.audio.blocks.16.mlp.0.weight', 'transformer.audio.blocks.16.mlp.2.bias', 'transformer.audio.blocks.16.mlp.2.weight', 'transformer.audio.blocks.16.mlp_ln.bias', 'transformer.audio.blocks.16.mlp_ln.weight', 'transformer.audio.blocks.17.attn.key.weight', 'transformer.audio.blocks.17.attn.out.bias', 'transformer.audio.blocks.17.attn.out.weight', 'transformer.audio.blocks.17.attn.query.bias', 'transformer.audio.blocks.17.attn.query.weight', 'transformer.audio.blocks.17.attn.value.bias', 'transformer.audio.blocks.17.attn.value.weight', 'transformer.audio.blocks.17.attn_ln.bias', 'transformer.audio.blocks.17.attn_ln.weight', 'transformer.audio.blocks.17.mlp.0.bias', 'transformer.audio.blocks.17.mlp.0.weight', 'transformer.audio.blocks.17.mlp.2.bias', 'transformer.audio.blocks.17.mlp.2.weight', 'transformer.audio.blocks.17.mlp_ln.bias', 'transformer.audio.blocks.17.mlp_ln.weight', 'transformer.audio.blocks.18.attn.key.weight', 'transformer.audio.blocks.18.attn.out.bias', 'transformer.audio.blocks.18.attn.out.weight', 'transformer.audio.blocks.18.attn.query.bias', 'transformer.audio.blocks.18.attn.query.weight', 'transformer.audio.blocks.18.attn.value.bias', 'transformer.audio.blocks.18.attn.value.weight', 'transformer.audio.blocks.18.attn_ln.bias', 'transformer.audio.blocks.18.attn_ln.weight', 'transformer.audio.blocks.18.mlp.0.bias', 'transformer.audio.blocks.18.mlp.0.weight', 'transformer.audio.blocks.18.mlp.2.bias', 'transformer.audio.blocks.18.mlp.2.weight', 'transformer.audio.blocks.18.mlp_ln.bias', 'transformer.audio.blocks.18.mlp_ln.weight', 'transformer.audio.blocks.19.attn.key.weight', 'transformer.audio.blocks.19.attn.out.bias', 'transformer.audio.blocks.19.attn.out.weight', 'transformer.audio.blocks.19.attn.query.bias', 'transformer.audio.blocks.19.attn.query.weight', 'transformer.audio.blocks.19.attn.value.bias', 'transformer.audio.blocks.19.attn.value.weight', 'transformer.audio.blocks.19.attn_ln.bias', 'transformer.audio.blocks.19.attn_ln.weight', 'transformer.audio.blocks.19.mlp.0.bias', 'transformer.audio.blocks.19.mlp.0.weight', 'transformer.audio.blocks.19.mlp.2.bias', 'transformer.audio.blocks.19.mlp.2.weight', 'transformer.audio.blocks.19.mlp_ln.bias', 'transformer.audio.blocks.19.mlp_ln.weight', 'transformer.audio.blocks.2.attn.key.weight', 'transformer.audio.blocks.2.attn.out.bias', 'transformer.audio.blocks.2.attn.out.weight', 'transformer.audio.blocks.2.attn.query.bias', 'transformer.audio.blocks.2.attn.query.weight', 'transformer.audio.blocks.2.attn.value.bias', 'transformer.audio.blocks.2.attn.value.weight', 'transformer.audio.blocks.2.attn_ln.bias', 'transformer.audio.blocks.2.attn_ln.weight', 'transformer.audio.blocks.2.mlp.0.bias', 'transformer.audio.blocks.2.mlp.0.weight', 'transformer.audio.blocks.2.mlp.2.bias', 'transformer.audio.blocks.2.mlp.2.weight', 'transformer.audio.blocks.2.mlp_ln.bias', 'transformer.audio.blocks.2.mlp_ln.weight', 'transformer.audio.blocks.20.attn.key.weight', 'transformer.audio.blocks.20.attn.out.bias', 'transformer.audio.blocks.20.attn.out.weight', 'transformer.audio.blocks.20.attn.query.bias', 'transformer.audio.blocks.20.attn.query.weight', 'transformer.audio.blocks.20.attn.value.bias', 'transformer.audio.blocks.20.attn.value.weight', 'transformer.audio.blocks.20.attn_ln.bias', 'transformer.audio.blocks.20.attn_ln.weight', 'transformer.audio.blocks.20.mlp.0.bias', 'transformer.audio.blocks.20.mlp.0.weight', 'transformer.audio.blocks.20.mlp.2.bias', 'transformer.audio.blocks.20.mlp.2.weight', 'transformer.audio.blocks.20.mlp_ln.bias', 'transformer.audio.blocks.20.mlp_ln.weight', 'transformer.audio.blocks.21.attn.key.weight', 'transformer.audio.blocks.21.attn.out.bias', 'transformer.audio.blocks.21.attn.out.weight', 'transformer.audio.blocks.21.attn.query.bias', 'transformer.audio.blocks.21.attn.query.weight', 'transformer.audio.blocks.21.attn.value.bias', 'transformer.audio.blocks.21.attn.value.weight', 'transformer.audio.blocks.21.attn_ln.bias', 'transformer.audio.blocks.21.attn_ln.weight', 'transformer.audio.blocks.21.mlp.0.bias', 'transformer.audio.blocks.21.mlp.0.weight', 'transformer.audio.blocks.21.mlp.2.bias', 'transformer.audio.blocks.21.mlp.2.weight', 'transformer.audio.blocks.21.mlp_ln.bias', 'transformer.audio.blocks.21.mlp_ln.weight', 'transformer.audio.blocks.22.attn.key.weight', 'transformer.audio.blocks.22.attn.out.bias', 'transformer.audio.blocks.22.attn.out.weight', 'transformer.audio.blocks.22.attn.query.bias', 'transformer.audio.blocks.22.attn.query.weight', 'transformer.audio.blocks.22.attn.value.bias', 'transformer.audio.blocks.22.attn.value.weight', 'transformer.audio.blocks.22.attn_ln.bias', 'transformer.audio.blocks.22.attn_ln.weight', 'transformer.audio.blocks.22.mlp.0.bias', 'transformer.audio.blocks.22.mlp.0.weight', 'transformer.audio.blocks.22.mlp.2.bias', 'transformer.audio.blocks.22.mlp.2.weight', 'transformer.audio.blocks.22.mlp_ln.bias', 'transformer.audio.blocks.22.mlp_ln.weight', 'transformer.audio.blocks.23.attn.key.weight', 'transformer.audio.blocks.23.attn.out.bias', 'transformer.audio.blocks.23.attn.out.weight', 'transformer.audio.blocks.23.attn.query.bias', 'transformer.audio.blocks.23.attn.query.weight', 'transformer.audio.blocks.23.attn.value.bias', 'transformer.audio.blocks.23.attn.value.weight', 'transformer.audio.blocks.23.attn_ln.bias', 'transformer.audio.blocks.23.attn_ln.weight', 'transformer.audio.blocks.23.mlp.0.bias', 'transformer.audio.blocks.23.mlp.0.weight', 'transformer.audio.blocks.23.mlp.2.bias', 'transformer.audio.blocks.23.mlp.2.weight', 'transformer.audio.blocks.23.mlp_ln.bias', 'transformer.audio.blocks.23.mlp_ln.weight', 'transformer.audio.blocks.24.attn.key.weight', 'transformer.audio.blocks.24.attn.out.bias', 'transformer.audio.blocks.24.attn.out.weight', 'transformer.audio.blocks.24.attn.query.bias', 'transformer.audio.blocks.24.attn.query.weight', 'transformer.audio.blocks.24.attn.value.bias', 'transformer.audio.blocks.24.attn.value.weight', 'transformer.audio.blocks.24.attn_ln.bias', 'transformer.audio.blocks.24.attn_ln.weight', 'transformer.audio.blocks.24.mlp.0.bias', 'transformer.audio.blocks.24.mlp.0.weight', 'transformer.audio.blocks.24.mlp.2.bias', 'transformer.audio.blocks.24.mlp.2.weight', 'transformer.audio.blocks.24.mlp_ln.bias', 'transformer.audio.blocks.24.mlp_ln.weight', 'transformer.audio.blocks.25.attn.key.weight', 'transformer.audio.blocks.25.attn.out.bias', 'transformer.audio.blocks.25.attn.out.weight', 'transformer.audio.blocks.25.attn.query.bias', 'transformer.audio.blocks.25.attn.query.weight', 'transformer.audio.blocks.25.attn.value.bias', 'transformer.audio.blocks.25.attn.value.weight', 'transformer.audio.blocks.25.attn_ln.bias', 'transformer.audio.blocks.25.attn_ln.weight', 'transformer.audio.blocks.25.mlp.0.bias', 'transformer.audio.blocks.25.mlp.0.weight', 'transformer.audio.blocks.25.mlp.2.bias', 'transformer.audio.blocks.25.mlp.2.weight', 'transformer.audio.blocks.25.mlp_ln.bias', 'transformer.audio.blocks.25.mlp_ln.weight', 'transformer.audio.blocks.26.attn.key.weight', 'transformer.audio.blocks.26.attn.out.bias', 'transformer.audio.blocks.26.attn.out.weight', 'transformer.audio.blocks.26.attn.query.bias', 'transformer.audio.blocks.26.attn.query.weight', 'transformer.audio.blocks.26.attn.value.bias', 'transformer.audio.blocks.26.attn.value.weight', 'transformer.audio.blocks.26.attn_ln.bias', 'transformer.audio.blocks.26.attn_ln.weight', 'transformer.audio.blocks.26.mlp.0.bias', 'transformer.audio.blocks.26.mlp.0.weight', 'transformer.audio.blocks.26.mlp.2.bias', 'transformer.audio.blocks.26.mlp.2.weight', 'transformer.audio.blocks.26.mlp_ln.bias', 'transformer.audio.blocks.26.mlp_ln.weight', 'transformer.audio.blocks.27.attn.key.weight', 'transformer.audio.blocks.27.attn.out.bias', 'transformer.audio.blocks.27.attn.out.weight', 'transformer.audio.blocks.27.attn.query.bias', 'transformer.audio.blocks.27.attn.query.weight', 'transformer.audio.blocks.27.attn.value.bias', 'transformer.audio.blocks.27.attn.value.weight', 'transformer.audio.blocks.27.attn_ln.bias', 'transformer.audio.blocks.27.attn_ln.weight', 'transformer.audio.blocks.27.mlp.0.bias', 'transformer.audio.blocks.27.mlp.0.weight', 'transformer.audio.blocks.27.mlp.2.bias', 'transformer.audio.blocks.27.mlp.2.weight', 'transformer.audio.blocks.27.mlp_ln.bias', 'transformer.audio.blocks.27.mlp_ln.weight', 'transformer.audio.blocks.28.attn.key.weight', 'transformer.audio.blocks.28.attn.out.bias', 'transformer.audio.blocks.28.attn.out.weight', 'transformer.audio.blocks.28.attn.query.bias', 'transformer.audio.blocks.28.attn.query.weight', 'transformer.audio.blocks.28.attn.value.bias', 'transformer.audio.blocks.28.attn.value.weight', 'transformer.audio.blocks.28.attn_ln.bias', 'transformer.audio.blocks.28.attn_ln.weight', 'transformer.audio.blocks.28.mlp.0.bias', 'transformer.audio.blocks.28.mlp.0.weight', 'transformer.audio.blocks.28.mlp.2.bias', 'transformer.audio.blocks.28.mlp.2.weight', 'transformer.audio.blocks.28.mlp_ln.bias', 'transformer.audio.blocks.28.mlp_ln.weight', 'transformer.audio.blocks.29.attn.key.weight', 'transformer.audio.blocks.29.attn.out.bias', 'transformer.audio.blocks.29.attn.out.weight', 'transformer.audio.blocks.29.attn.query.bias', 'transformer.audio.blocks.29.attn.query.weight', 'transformer.audio.blocks.29.attn.value.bias', 'transformer.audio.blocks.29.attn.value.weight', 'transformer.audio.blocks.29.attn_ln.bias', 'transformer.audio.blocks.29.attn_ln.weight', 'transformer.audio.blocks.29.mlp.0.bias', 'transformer.audio.blocks.29.mlp.0.weight', 'transformer.audio.blocks.29.mlp.2.bias', 'transformer.audio.blocks.29.mlp.2.weight', 'transformer.audio.blocks.29.mlp_ln.bias', 'transformer.audio.blocks.29.mlp_ln.weight', 'transformer.audio.blocks.3.attn.key.weight', 'transformer.audio.blocks.3.attn.out.bias', 'transformer.audio.blocks.3.attn.out.weight', 'transformer.audio.blocks.3.attn.query.bias', 'transformer.audio.blocks.3.attn.query.weight', 'transformer.audio.blocks.3.attn.value.bias', 'transformer.audio.blocks.3.attn.value.weight', 'transformer.audio.blocks.3.attn_ln.bias', 'transformer.audio.blocks.3.attn_ln.weight', 'transformer.audio.blocks.3.mlp.0.bias', 'transformer.audio.blocks.3.mlp.0.weight', 'transformer.audio.blocks.3.mlp.2.bias', 'transformer.audio.blocks.3.mlp.2.weight', 'transformer.audio.blocks.3.mlp_ln.bias', 'transformer.audio.blocks.3.mlp_ln.weight', 'transformer.audio.blocks.30.attn.key.weight', 'transformer.audio.blocks.30.attn.out.bias', 'transformer.audio.blocks.30.attn.out.weight', 'transformer.audio.blocks.30.attn.query.bias', 'transformer.audio.blocks.30.attn.query.weight', 'transformer.audio.blocks.30.attn.value.bias', 'transformer.audio.blocks.30.attn.value.weight', 'transformer.audio.blocks.30.attn_ln.bias', 'transformer.audio.blocks.30.attn_ln.weight', 'transformer.audio.blocks.30.mlp.0.bias', 'transformer.audio.blocks.30.mlp.0.weight', 'transformer.audio.blocks.30.mlp.2.bias', 'transformer.audio.blocks.30.mlp.2.weight', 'transformer.audio.blocks.30.mlp_ln.bias', 'transformer.audio.blocks.30.mlp_ln.weight', 'transformer.audio.blocks.31.attn.key.weight', 'transformer.audio.blocks.31.attn.out.bias', 'transformer.audio.blocks.31.attn.out.weight', 'transformer.audio.blocks.31.attn.query.bias', 'transformer.audio.blocks.31.attn.query.weight', 'transformer.audio.blocks.31.attn.value.bias', 'transformer.audio.blocks.31.attn.value.weight', 'transformer.audio.blocks.31.attn_ln.bias', 'transformer.audio.blocks.31.attn_ln.weight', 'transformer.audio.blocks.31.mlp.0.bias', 'transformer.audio.blocks.31.mlp.0.weight', 'transformer.audio.blocks.31.mlp.2.bias', 'transformer.audio.blocks.31.mlp.2.weight', 'transformer.audio.blocks.31.mlp_ln.bias', 'transformer.audio.blocks.31.mlp_ln.weight', 'transformer.audio.blocks.4.attn.key.weight', 'transformer.audio.blocks.4.attn.out.bias', 'transformer.audio.blocks.4.attn.out.weight', 'transformer.audio.blocks.4.attn.query.bias', 'transformer.audio.blocks.4.attn.query.weight', 'transformer.audio.blocks.4.attn.value.bias', 'transformer.audio.blocks.4.attn.value.weight', 'transformer.audio.blocks.4.attn_ln.bias', 'transformer.audio.blocks.4.attn_ln.weight', 'transformer.audio.blocks.4.mlp.0.bias', 'transformer.audio.blocks.4.mlp.0.weight', 'transformer.audio.blocks.4.mlp.2.bias', 'transformer.audio.blocks.4.mlp.2.weight', 'transformer.audio.blocks.4.mlp_ln.bias', 'transformer.audio.blocks.4.mlp_ln.weight', 'transformer.audio.blocks.5.attn.key.weight', 'transformer.audio.blocks.5.attn.out.bias', 'transformer.audio.blocks.5.attn.out.weight', 'transformer.audio.blocks.5.attn.query.bias', 'transformer.audio.blocks.5.attn.query.weight', 'transformer.audio.blocks.5.attn.value.bias', 'transformer.audio.blocks.5.attn.value.weight', 'transformer.audio.blocks.5.attn_ln.bias', 'transformer.audio.blocks.5.attn_ln.weight', 'transformer.audio.blocks.5.mlp.0.bias', 'transformer.audio.blocks.5.mlp.0.weight', 'transformer.audio.blocks.5.mlp.2.bias', 'transformer.audio.blocks.5.mlp.2.weight', 'transformer.audio.blocks.5.mlp_ln.bias', 'transformer.audio.blocks.5.mlp_ln.weight', 'transformer.audio.blocks.6.attn.key.weight', 'transformer.audio.blocks.6.attn.out.bias', 'transformer.audio.blocks.6.attn.out.weight', 'transformer.audio.blocks.6.attn.query.bias', 'transformer.audio.blocks.6.attn.query.weight', 'transformer.audio.blocks.6.attn.value.bias', 'transformer.audio.blocks.6.attn.value.weight', 'transformer.audio.blocks.6.attn_ln.bias', 'transformer.audio.blocks.6.attn_ln.weight', 'transformer.audio.blocks.6.mlp.0.bias', 'transformer.audio.blocks.6.mlp.0.weight', 'transformer.audio.blocks.6.mlp.2.bias', 'transformer.audio.blocks.6.mlp.2.weight', 'transformer.audio.blocks.6.mlp_ln.bias', 'transformer.audio.blocks.6.mlp_ln.weight', 'transformer.audio.blocks.7.attn.key.weight', 'transformer.audio.blocks.7.attn.out.bias', 'transformer.audio.blocks.7.attn.out.weight', 'transformer.audio.blocks.7.attn.query.bias', 'transformer.audio.blocks.7.attn.query.weight', 'transformer.audio.blocks.7.attn.value.bias', 'transformer.audio.blocks.7.attn.value.weight', 'transformer.audio.blocks.7.attn_ln.bias', 'transformer.audio.blocks.7.attn_ln.weight', 'transformer.audio.blocks.7.mlp.0.bias', 'transformer.audio.blocks.7.mlp.0.weight', 'transformer.audio.blocks.7.mlp.2.bias', 'transformer.audio.blocks.7.mlp.2.weight', 'transformer.audio.blocks.7.mlp_ln.bias', 'transformer.audio.blocks.7.mlp_ln.weight', 'transformer.audio.blocks.8.attn.key.weight', 'transformer.audio.blocks.8.attn.out.bias', 'transformer.audio.blocks.8.attn.out.weight', 'transformer.audio.blocks.8.attn.query.bias', 'transformer.audio.blocks.8.attn.query.weight', 'transformer.audio.blocks.8.attn.value.bias', 'transformer.audio.blocks.8.attn.value.weight', 'transformer.audio.blocks.8.attn_ln.bias', 'transformer.audio.blocks.8.attn_ln.weight', 'transformer.audio.blocks.8.mlp.0.bias', 'transformer.audio.blocks.8.mlp.0.weight', 'transformer.audio.blocks.8.mlp.2.bias', 'transformer.audio.blocks.8.mlp.2.weight', 'transformer.audio.blocks.8.mlp_ln.bias', 'transformer.audio.blocks.8.mlp_ln.weight', 'transformer.audio.blocks.9.attn.key.weight', 'transformer.audio.blocks.9.attn.out.bias', 'transformer.audio.blocks.9.attn.out.weight', 'transformer.audio.blocks.9.attn.query.bias', 'transformer.audio.blocks.9.attn.query.weight', 'transformer.audio.blocks.9.attn.value.bias', 'transformer.audio.blocks.9.attn.value.weight', 'transformer.audio.blocks.9.attn_ln.bias', 'transformer.audio.blocks.9.attn_ln.weight', 'transformer.audio.blocks.9.mlp.0.bias', 'transformer.audio.blocks.9.mlp.0.weight', 'transformer.audio.blocks.9.mlp.2.bias', 'transformer.audio.blocks.9.mlp.2.weight', 'transformer.audio.blocks.9.mlp_ln.bias', 'transformer.audio.blocks.9.mlp_ln.weight', 'transformer.h.1.attn.c_attn.bias', 'transformer.h.1.attn.c_attn.weight', 'transformer.h.1.attn.c_proj.weight', 'transformer.h.1.ln_1.weight', 'transformer.h.1.ln_2.weight', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.1.mlp.w1.weight', 'transformer.h.1.mlp.w2.weight', 'transformer.h.10.attn.c_attn.bias', 'transformer.h.10.attn.c_attn.weight', 'transformer.h.10.attn.c_proj.weight', 'transformer.h.10.ln_1.weight', 'transformer.h.10.ln_2.weight', 'transformer.h.10.mlp.c_proj.weight', 'transformer.h.10.mlp.w1.weight', 'transformer.h.10.mlp.w2.weight', 'transformer.h.11.attn.c_attn.bias', 'transformer.h.11.attn.c_attn.weight', 'transformer.h.11.attn.c_proj.weight', 'transformer.h.11.ln_1.weight', 'transformer.h.11.ln_2.weight', 'transformer.h.11.mlp.c_proj.weight', 'transformer.h.11.mlp.w1.weight', 'transformer.h.11.mlp.w2.weight', 'transformer.h.12.attn.c_attn.bias', 'transformer.h.12.attn.c_attn.weight', 'transformer.h.12.attn.c_proj.weight', 'transformer.h.12.ln_1.weight', 'transformer.h.12.ln_2.weight', 'transformer.h.12.mlp.c_proj.weight', 'transformer.h.12.mlp.w1.weight', 'transformer.h.12.mlp.w2.weight', 'transformer.h.13.attn.c_attn.bias', 'transformer.h.13.attn.c_attn.weight', 'transformer.h.13.attn.c_proj.weight', 'transformer.h.13.ln_1.weight', 'transformer.h.13.ln_2.weight', 'transformer.h.13.mlp.c_proj.weight', 'transformer.h.13.mlp.w1.weight', 'transformer.h.13.mlp.w2.weight', 'transformer.h.14.attn.c_attn.bias', 'transformer.h.14.attn.c_attn.weight', 'transformer.h.14.attn.c_proj.weight', 'transformer.h.14.ln_1.weight', 'transformer.h.14.ln_2.weight', 'transformer.h.14.mlp.c_proj.weight', 'transformer.h.14.mlp.w1.weight', 'transformer.h.14.mlp.w2.weight', 'transformer.h.15.attn.c_attn.bias', 'transformer.h.15.attn.c_attn.weight', 'transformer.h.15.attn.c_proj.weight', 'transformer.h.15.ln_1.weight', 'transformer.h.15.ln_2.weight', 'transformer.h.15.mlp.c_proj.weight', 'transformer.h.15.mlp.w1.weight', 'transformer.h.15.mlp.w2.weight', 'transformer.h.16.attn.c_attn.bias', 'transformer.h.16.attn.c_attn.weight', 'transformer.h.16.attn.c_proj.weight', 'transformer.h.16.ln_1.weight', 'transformer.h.16.ln_2.weight', 'transformer.h.16.mlp.c_proj.weight', 'transformer.h.16.mlp.w1.weight', 'transformer.h.16.mlp.w2.weight', 'transformer.h.17.attn.c_attn.bias', 'transformer.h.17.attn.c_attn.weight', 'transformer.h.17.attn.c_proj.weight', 'transformer.h.17.ln_1.weight', 'transformer.h.17.ln_2.weight', 'transformer.h.17.mlp.c_proj.weight', 'transformer.h.17.mlp.w1.weight', 'transformer.h.17.mlp.w2.weight', 'transformer.h.18.attn.c_attn.bias', 'transformer.h.18.attn.c_attn.weight', 'transformer.h.18.attn.c_proj.weight', 'transformer.h.18.ln_1.weight', 'transformer.h.18.ln_2.weight', 'transformer.h.18.mlp.c_proj.weight', 'transformer.h.18.mlp.w1.weight', 'transformer.h.18.mlp.w2.weight', 'transformer.h.19.attn.c_attn.bias', 'transformer.h.19.attn.c_attn.weight', 'transformer.h.19.attn.c_proj.weight', 'transformer.h.19.ln_1.weight', 'transformer.h.19.ln_2.weight', 'transformer.h.19.mlp.c_proj.weight', 'transformer.h.19.mlp.w1.weight', 'transformer.h.19.mlp.w2.weight', 'transformer.h.2.attn.c_attn.bias', 'transformer.h.2.attn.c_attn.weight', 'transformer.h.2.attn.c_proj.weight', 'transformer.h.2.ln_1.weight', 'transformer.h.2.ln_2.weight', 'transformer.h.2.mlp.c_proj.weight', 'transformer.h.2.mlp.w1.weight', 'transformer.h.2.mlp.w2.weight', 'transformer.h.20.attn.c_attn.bias', 'transformer.h.20.attn.c_attn.weight', 'transformer.h.20.attn.c_proj.weight', 'transformer.h.20.ln_1.weight', 'transformer.h.20.ln_2.weight', 'transformer.h.20.mlp.c_proj.weight', 'transformer.h.20.mlp.w1.weight', 'transformer.h.20.mlp.w2.weight', 'transformer.h.21.attn.c_attn.bias', 'transformer.h.21.attn.c_attn.weight', 'transformer.h.21.attn.c_proj.weight', 'transformer.h.21.ln_1.weight', 'transformer.h.21.ln_2.weight', 'transformer.h.21.mlp.c_proj.weight', 'transformer.h.21.mlp.w1.weight', 'transformer.h.21.mlp.w2.weight', 'transformer.h.22.attn.c_attn.bias', 'transformer.h.22.attn.c_attn.weight', 'transformer.h.22.attn.c_proj.weight', 'transformer.h.22.ln_1.weight', 'transformer.h.22.ln_2.weight', 'transformer.h.22.mlp.c_proj.weight', 'transformer.h.22.mlp.w1.weight', 'transformer.h.22.mlp.w2.weight', 'transformer.h.23.attn.c_attn.bias', 'transformer.h.23.attn.c_attn.weight', 'transformer.h.23.attn.c_proj.weight', 'transformer.h.23.ln_1.weight', 'transformer.h.23.ln_2.weight', 'transformer.h.23.mlp.c_proj.weight', 'transformer.h.23.mlp.w1.weight', 'transformer.h.23.mlp.w2.weight', 'transformer.h.24.attn.c_attn.bias', 'transformer.h.24.attn.c_attn.weight', 'transformer.h.24.attn.c_proj.weight', 'transformer.h.24.ln_1.weight', 'transformer.h.24.ln_2.weight', 'transformer.h.24.mlp.c_proj.weight', 'transformer.h.24.mlp.w1.weight', 'transformer.h.24.mlp.w2.weight', 'transformer.h.25.attn.c_attn.bias', 'transformer.h.25.attn.c_attn.weight', 'transformer.h.25.attn.c_proj.weight', 'transformer.h.25.ln_1.weight', 'transformer.h.25.ln_2.weight', 'transformer.h.25.mlp.c_proj.weight', 'transformer.h.25.mlp.w1.weight', 'transformer.h.25.mlp.w2.weight', 'transformer.h.26.attn.c_attn.bias', 'transformer.h.26.attn.c_attn.weight', 'transformer.h.26.attn.c_proj.weight', 'transformer.h.26.ln_1.weight', 'transformer.h.26.ln_2.weight', 'transformer.h.26.mlp.c_proj.weight', 'transformer.h.26.mlp.w1.weight', 'transformer.h.26.mlp.w2.weight', 'transformer.h.27.attn.c_attn.bias', 'transformer.h.27.attn.c_attn.weight', 'transformer.h.27.attn.c_proj.weight', 'transformer.h.27.ln_1.weight', 'transformer.h.27.ln_2.weight', 'transformer.h.27.mlp.c_proj.weight', 'transformer.h.27.mlp.w1.weight', 'transformer.h.27.mlp.w2.weight', 'transformer.h.28.attn.c_attn.bias', 'transformer.h.28.attn.c_attn.weight', 'transformer.h.28.attn.c_proj.weight', 'transformer.h.28.ln_1.weight', 'transformer.h.28.ln_2.weight', 'transformer.h.28.mlp.c_proj.weight', 'transformer.h.28.mlp.w1.weight', 'transformer.h.28.mlp.w2.weight', 'transformer.h.29.attn.c_attn.bias', 'transformer.h.29.attn.c_attn.weight', 'transformer.h.29.attn.c_proj.weight', 'transformer.h.29.ln_1.weight', 'transformer.h.29.ln_2.weight', 'transformer.h.29.mlp.c_proj.weight', 'transformer.h.29.mlp.w1.weight', 'transformer.h.29.mlp.w2.weight', 'transformer.h.3.attn.c_attn.bias', 'transformer.h.3.attn.c_attn.weight', 'transformer.h.3.attn.c_proj.weight', 'transformer.h.3.ln_1.weight', 'transformer.h.3.ln_2.weight', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.3.mlp.w1.weight', 'transformer.h.3.mlp.w2.weight', 'transformer.h.30.attn.c_attn.bias', 'transformer.h.30.attn.c_attn.weight', 'transformer.h.30.attn.c_proj.weight', 'transformer.h.30.ln_1.weight', 'transformer.h.30.ln_2.weight', 'transformer.h.30.mlp.c_proj.weight', 'transformer.h.30.mlp.w1.weight', 'transformer.h.30.mlp.w2.weight', 'transformer.h.31.attn.c_attn.bias', 'transformer.h.31.attn.c_attn.weight', 'transformer.h.31.attn.c_proj.weight', 'transformer.h.31.ln_1.weight', 'transformer.h.31.ln_2.weight', 'transformer.h.31.mlp.c_proj.weight', 'transformer.h.31.mlp.w1.weight', 'transformer.h.31.mlp.w2.weight', 'transformer.h.4.attn.c_attn.bias', 'transformer.h.4.attn.c_attn.weight', 'transformer.h.4.attn.c_proj.weight', 'transformer.h.4.ln_1.weight', 'transformer.h.4.ln_2.weight', 'transformer.h.4.mlp.c_proj.weight', 'transformer.h.4.mlp.w1.weight', 'transformer.h.4.mlp.w2.weight', 'transformer.h.5.attn.c_attn.bias', 'transformer.h.5.attn.c_attn.weight', 'transformer.h.5.attn.c_proj.weight', 'transformer.h.5.ln_1.weight', 'transformer.h.5.ln_2.weight', 'transformer.h.5.mlp.c_proj.weight', 'transformer.h.5.mlp.w1.weight', 'transformer.h.5.mlp.w2.weight', 'transformer.h.6.attn.c_attn.bias', 'transformer.h.6.attn.c_attn.weight', 'transformer.h.6.attn.c_proj.weight', 'transformer.h.6.ln_1.weight', 'transformer.h.6.ln_2.weight', 'transformer.h.6.mlp.c_proj.weight', 'transformer.h.6.mlp.w1.weight', 'transformer.h.6.mlp.w2.weight', 'transformer.h.7.attn.c_attn.bias', 'transformer.h.7.attn.c_attn.weight', 'transformer.h.7.attn.c_proj.weight', 'transformer.h.7.ln_1.weight', 'transformer.h.7.ln_2.weight', 'transformer.h.7.mlp.c_proj.weight', 'transformer.h.7.mlp.w1.weight', 'transformer.h.7.mlp.w2.weight', 'transformer.h.8.attn.c_attn.bias', 'transformer.h.8.attn.c_attn.weight', 'transformer.h.8.attn.c_proj.weight', 'transformer.h.8.ln_1.weight', 'transformer.h.8.ln_2.weight', 'transformer.h.8.mlp.c_proj.weight', 'transformer.h.8.mlp.w1.weight', 'transformer.h.8.mlp.w2.weight', 'transformer.h.9.attn.c_attn.bias', 'transformer.h.9.attn.c_attn.weight', 'transformer.h.9.attn.c_proj.weight', 'transformer.h.9.ln_1.weight', 'transformer.h.9.ln_2.weight', 'transformer.h.9.mlp.c_proj.weight', 'transformer.h.9.mlp.w1.weight', 'transformer.h.9.mlp.w2.weight']\n",
      "- This IS expected if you are initializing QWenLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing QWenLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio_start_id: 155163, audio_end_id: 155164, audio_pad_id: 151851.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QWenLMHeadModel(\n",
       "  (transformer): QWenModel(\n",
       "    (wte): Embedding(155947, 4096)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (rotary_emb): RotaryEmbedding()\n",
       "    (h): ModuleList(\n",
       "      (0): QWenBlock(\n",
       "        (ln_1): RMSNorm()\n",
       "        (attn): QWenAttention(\n",
       "          (c_attn): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): RMSNorm()\n",
       "        (mlp): QWenMLP(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (c_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): RMSNorm()\n",
       "    (audio): AudioEncoder(\n",
       "      (conv1): Conv1d(80, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (blocks): ModuleList(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiHeadAttention(\n",
       "            (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (attn_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          )\n",
       "          (mlp_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (ln_post): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (avg_pooler): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "      (proj): Linear(in_features=1280, out_features=4096, bias=True)\n",
       "      (audio_bos_eos_token): Embedding(2, 4096)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=155947, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tokenizer = build_model(args)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''这段函数的作用\n",
    "由于我的数据集是一个jsonl的文件，每一条的sample的格式如下：\n",
    "a = {\"messages\": [{\"role\": \"user\", \"audio\": \"/root/autodl-tmp/audio_data/neutral_337-364_0359.wav\", \"content\": \"说话者在音频中提到了什么？\"}, {\"role\": \"assistant\", \"content\": \"Earth and gravel seemed to fill the pan. 锅里似乎装满了泥土和沙砾。\"}]}\n",
    "这个函数用于将其转换为qwen audio的标准输出，{\"input_ids\", \"attention_mask\", \"labels\", \"audio_info\"}\n",
    "\n",
    "padding和转换为batch的事情，是在collect_fn里面完成\n",
    "'''\n",
    "\n",
    "# 我这里写的是单条数据的process，并不是对于整个数据集的jsonl的统一处理\n",
    "def process(sources, tokenizer: QWenTokenizer, system_prompt=\"You are a helpful assistant.\"):\n",
    "    special_tokens = tokenizer.AUDIO_ST\n",
    "\n",
    "    im_start = tokenizer.im_start_id\n",
    "    im_end = tokenizer.im_end_id\n",
    "    nl_token = tokenizer.encode(\"\\n\")\n",
    "\n",
    "\n",
    "    # system prompt\n",
    "    system_tokens = tokenizer.encode(text=f'{\"system\"}\\n{system_prompt}', special_tokens=special_tokens)\n",
    "    system_label = [im_start] + (len(system_tokens) - 3) * [IGNORE_TOKEN_ID] + [im_end] + nl_token\n",
    "    raw_system_text = IMSTART + system_prompt + IMEND + '\\n'\n",
    "\n",
    "    assert len(system_tokens) == len(system_label)\n",
    "    \"Unknown bugs when encoding system prompt in function 'process'. \"\n",
    "\n",
    "    input_ids = []; labels = []; audio_infos = []\n",
    "\n",
    "    input_ids.append(system_tokens)\n",
    "    labels.append(system_label)\n",
    "    \n",
    "\n",
    "    for i, ele in enumerate(sources['messages']):\n",
    "\n",
    "        if i == 0:\n",
    "            assert ele['role'] == \"user\"\n",
    "\n",
    "            \"The first sentence must be asked by human.\"\n",
    "\n",
    "            audio_info = tokenizer.process_audio(('<audio>' + ele['audio'] + '</audio>'))\n",
    "\n",
    "            _text_tokens = tokenizer.encode(ele['content'], special_tokens=set(tokenizer.AUDIO_ST), audio_info=audio_info)\n",
    "            _label_tokens = [im_start] + (len(_text_tokens) - 3) * [IGNORE_TOKEN_ID] + [im_end] + nl_token\n",
    "            raw_text = IMSTART + ele['content'] + IMEND + '\\n'\n",
    "\n",
    "\n",
    "            audio_infos.append(audio_info)\n",
    "\n",
    "        else:\n",
    "            if ele['role'] == 'user':\n",
    "                audio_info = tokenizer.process_audio(text=ele['audio']) if 'audio' in ele.keys() else None\n",
    "\n",
    "                # 这里面最开始没有encode\"<im_sart>\"这样的tokens，所以要加上，然后target算的时候要注意，只有中间的部分是ignore，开始和结束以及换行符需要算loss.                \n",
    "                _text_tokens_part = tokenizer.encode(f\"'user\\n'+ {ele['content']}\", special_tokens=set(tokenizer.AUDIO_ST), audio_info=audio_info)\n",
    "                _text_tokens = [im_start] + _text_tokens_part + [im_end] + nl_token\n",
    "                \n",
    "                _label_tokens = [im_start] + (len(_text_tokens) - 3) * [IGNORE_TOKEN_ID] + [im_end] + nl_token\n",
    "                raw_text = IMSTART + ele['content'] + IMEND + '\\n'\n",
    "\n",
    "            else:\n",
    "                _text_tokens_part = tokenizer.encode(f\"'assitant\\n' + {ele['content']}\", special_tokens=set(tokenizer.AUDIO_ST), audio_info=audio_info)\n",
    "                _text_tokens = [im_start] + _text_tokens_part + [im_end] + nl_token\n",
    "\n",
    "                # 这里面的assistant这个词需要mask，只在具体的answer的句子上算loss即可; 所以这里面前面3个tokens不要\n",
    "                _label_tokens = [im_start] + [IGNORE_TOKEN_ID] * 2 + _text_tokens[3:-2] + [im_end] + nl_token \n",
    "                # _label_tokens = [im_start] + (len(_text_tokens) - 3) * [tokenizer.pad_token_id] + [im_end] + nl_tokens\n",
    "                raw_text = IMSTART + ele['content'] + IMEND + '\\n'\n",
    "\n",
    "        # TODO: 这里只有单轮对话、单段音频输入\n",
    "        input_ids.append(_text_tokens)\n",
    "        labels.append(_label_tokens)\n",
    "\n",
    "\n",
    "        raw_system_text += raw_text\n",
    "        raw_text_all = raw_system_text\n",
    "\n",
    "        # 这里的input_ids还不是tensor，因为我不想直接全部padding到max_len\n",
    "        attention_mask = [[1 if token != tokenizer.pad_token_id else 0 for token in seq] for seq in input_ids]\n",
    "\n",
    "\n",
    "        for i in range(len(input_ids)):\n",
    "\n",
    "                assert len(input_ids[i]) == len(labels[i])\n",
    "\n",
    "    return (input_ids, labels,  audio_infos, raw_text_all,  attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, data_path, tokenizer) -> None:\n",
    "        super().__init__()\n",
    "        self.data_path =data_path # jsonl\n",
    "        self.tokenizer = tokenizer\n",
    "        self.build_dataset()\n",
    "\n",
    "    def build_dataset(self):\n",
    "        data = read_jsonl(self.data_path) # single conversation turn\n",
    "        self.data = data\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        element = self.data[index]\n",
    "        input_ids, labels, audio_infos, _, attention_mask = process(element, tokenizer=self.tokenizer)\n",
    "        return {\"input_ids\": input_ids, \"labels\": labels, \"audio_info\": audio_infos, \"attention_mask\": attention_mask}\n",
    "    \n",
    "\n",
    "test_dataset = AudioDataset(data_path=\"/root/codes/MyQwenAudio/data/emov_db/qa_data.jsonl\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "\n",
    "def pad_nested_sequence(sequences, pad_value):\n",
    "    \"\"\"\n",
    "    填充嵌套的序列，使每个子序列和整体序列达到一致的长度。\n",
    "\n",
    "    Args:\n",
    "        sequences (List[List[List[int]]]): 嵌套的序列。\n",
    "        pad_value (int): 填充值。\n",
    "\n",
    "    Returns:\n",
    "        List[List[int]]: 填充后的序列。\n",
    "    \"\"\"\n",
    "    max_outer_len = max(len(seq) for seq in sequences)  # 外层最大长度\n",
    "    max_inner_len = max(len(subseq) for seq in sequences for subseq in seq)  # 内层最大长度\n",
    "\n",
    "    padded = []\n",
    "    for seq in sequences:\n",
    "        # 填充每个子序列到内层最大长度\n",
    "        padded_seq = [subseq + [pad_value] * (max_inner_len - len(subseq)) for subseq in seq]\n",
    "        # 填充外层序列到外层最大长度\n",
    "        padded_seq += [[pad_value] * max_inner_len] * (max_outer_len - len(padded_seq))\n",
    "        padded.append(padded_seq)\n",
    "    return padded\n",
    "\n",
    "def pad_sequence(sequences, max_len, pad_value):\n",
    "    return [seq + [pad_value] * (max_len - len(seq)) for seq in sequences]\n",
    "\n",
    "\n",
    "\n",
    "class CustomDataCollatorWithAudio(DataCollatorWithPadding):\n",
    "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        # 提取字段\n",
    "        input_ids_batch = [feature[\"input_ids\"] for feature in features]\n",
    "        labels_batch = [feature[\"labels\"] for feature in features]\n",
    "        attention_mask_batch = [feature[\"attention_mask\"] for feature in features]\n",
    "\n",
    "        audio_infos = [feature[\"audio_info\"][0] for feature in features]\n",
    "\n",
    "\n",
    "        # 填充 input_ids 和 labels 的嵌套序列\n",
    "        input_ids_padded = pad_nested_sequence(input_ids_batch, self.tokenizer.pad_token_id)\n",
    "        labels_padded = pad_nested_sequence(labels_batch, -100)  # 忽略位置\n",
    "        attention_mask_padded = pad_nested_sequence(attention_mask_batch, 0)\n",
    "\n",
    "        # 转换为张量\n",
    "        input_ids_tensor = torch.tensor(input_ids_padded, dtype=torch.long)\n",
    "        labels_tensor = torch.tensor(labels_padded, dtype=torch.long)\n",
    "\n",
    "        assert input_ids_tensor.shape == labels_tensor.shape\n",
    "\n",
    "\n",
    "        attention_mask_tensor = torch.tensor(attention_mask_padded, dtype=torch.long)\n",
    "\n",
    "\n",
    "        if any(audio_infos):\n",
    "\n",
    "            audio_span_tokens = []\n",
    "            for x in audio_infos:\n",
    "                audio_span_tokens.extend(x['audio_span_tokens'])\n",
    "\n",
    "            \n",
    "            audio_batch = {\n",
    "                \"input_audios\": torch.concat([info['input_audios'] for info in audio_infos if info]),\n",
    "                \"audio_span_tokens\": audio_span_tokens,\n",
    "                \"input_audio_lengths\": torch.concat([info['input_audio_lengths'] for info in audio_infos if info])\n",
    "            }\n",
    "\n",
    "        results = {\n",
    "            \"input_ids\": input_ids_tensor,\n",
    "            \"labels\": labels_tensor,\n",
    "            \"attention_mask\": attention_mask_tensor,\n",
    "        }\n",
    "\n",
    "        results['audio_info'] = audio_batch\n",
    "        \n",
    "        # 返回批次\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model \n",
    "tokenizer = tokenizer\n",
    "\n",
    "training_dataset = test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设已经初始化 tokenizer 和 test_dataset\n",
    "collator = CustomDataCollatorWithAudio(tokenizer=tokenizer)\n",
    "\n",
    "# 使用 DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "data_loader = DataLoader(test_dataset, batch_size=4, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_audios': tensor([[[ 0.1599,  0.0370,  0.3451,  ..., -0.6524, -0.6524, -0.6524],\n",
      "         [ 0.1338,  0.0713,  0.1803,  ..., -0.6524, -0.6524, -0.6524],\n",
      "         [ 0.0639,  0.1599, -0.0367,  ..., -0.6524, -0.6524, -0.6524],\n",
      "         ...,\n",
      "         [-0.6524, -0.6524, -0.6524,  ..., -0.6524, -0.6524, -0.6524],\n",
      "         [-0.6524, -0.6524, -0.6524,  ..., -0.6524, -0.6524, -0.6524],\n",
      "         [-0.6524, -0.6524, -0.6524,  ..., -0.6524, -0.6524, -0.6524]],\n",
      "\n",
      "        [[-0.1086,  0.3074,  0.2998,  ..., -0.4878, -0.4878, -0.4878],\n",
      "         [ 0.0073,  0.0364,  0.1590,  ..., -0.4878, -0.4878, -0.4878],\n",
      "         [ 0.0230,  0.0754,  0.1241,  ..., -0.4878, -0.4878, -0.4878],\n",
      "         ...,\n",
      "         [-0.4878, -0.4878, -0.4878,  ..., -0.4878, -0.4878, -0.4878],\n",
      "         [-0.4878, -0.4878, -0.4878,  ..., -0.4878, -0.4878, -0.4878],\n",
      "         [-0.4878, -0.4878, -0.4878,  ..., -0.4878, -0.4878, -0.4878]],\n",
      "\n",
      "        [[ 0.5025,  0.8418,  0.7762,  ..., -0.5493, -0.5493, -0.5493],\n",
      "         [ 0.6089,  0.6164,  0.6028,  ..., -0.5493, -0.5493, -0.5493],\n",
      "         [ 0.4450,  0.3319,  0.3674,  ..., -0.5493, -0.5493, -0.5493],\n",
      "         ...,\n",
      "         [-0.5493, -0.5493, -0.5493,  ..., -0.5493, -0.5493, -0.5493],\n",
      "         [-0.5493, -0.5493, -0.5493,  ..., -0.5493, -0.5493, -0.5493],\n",
      "         [-0.5493, -0.5493, -0.5493,  ..., -0.5493, -0.5493, -0.5493]],\n",
      "\n",
      "        [[ 0.3803,  0.2086,  0.3579,  ..., -0.6023, -0.6023, -0.6023],\n",
      "         [ 0.1650,  0.0726,  0.1829,  ..., -0.6023, -0.6023, -0.6023],\n",
      "         [ 0.0536,  0.0130,  0.0429,  ..., -0.6023, -0.6023, -0.6023],\n",
      "         ...,\n",
      "         [-0.6023, -0.5544, -0.6023,  ..., -0.6023, -0.6023, -0.6023],\n",
      "         [-0.6023, -0.6023, -0.6023,  ..., -0.6023, -0.6023, -0.6023],\n",
      "         [-0.6023, -0.6023, -0.6023,  ..., -0.6023, -0.6023, -0.6023]]]), 'audio_span_tokens': [119, 81, 127, 107], 'input_audio_lengths': tensor([[235, 117],\n",
      "        [159,  79],\n",
      "        [250, 125],\n",
      "        [210, 105]], dtype=torch.int32)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 遍历 DataLoader\n",
    "for batch in data_loader:\n",
    "    # print(batch)\n",
    "    # print(batch.keys())  # 包括 input_ids, attention_mask, labels, audio_info\n",
    "    print(batch[\"audio_info\"])  # 查看音频信息\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_178043/3544646053.py:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model, tokenizer=tokenizer, train_dataset=test_dataset, data_collator=collator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-20 22:40:19,667] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/root/miniconda3/compiler_compat/ld: warning: libpthread.so.0, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/root/miniconda3/compiler_compat/ld: warning: libstdc++.so.6, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/root/miniconda3/compiler_compat/ld: warning: libm.so.6, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::runtime_error::~runtime_error()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__gxx_personality_v0@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::tellp()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::chrono::_V2::steady_clock::now()@GLIBCXX_3.4.19'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_replace_aux(unsigned long, unsigned long, unsigned long, char)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for bool@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_logic_error(char const*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::logic_error@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::~locale()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::string const&, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_end_catch@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ofstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::logic_error::~logic_error()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for __cxxabiv1::__si_class_type_info@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::_M_cache_locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator new[](unsigned long)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_leak_hard()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ifstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >::basic_streambuf(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> > const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::string const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned short@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::resize(unsigned long, char)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for char const*@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ctype<char>::_M_widen_init() const@GLIBCXX_3.4.11'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_invalid_argument(char const*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::operator=(std::locale const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<wchar_t, std::char_traits<wchar_t> >::_M_cache_locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_decrement(std::_Rb_tree_node_base const*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_free_exception@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::notify_one()@GLIBCXX_3.4.11'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::Init::~Init()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::~basic_string()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_pure_virtual@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::flush()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for __cxxabiv1::__class_type_info@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_rethrow@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_fstream<char, std::char_traits<char> >::~basic_fstream()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::compare(char const*) const@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ostringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::locale()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::chrono::_V2::system_clock::now()@GLIBCXX_3.4.19'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ifstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Hash_bytes(void const*, unsigned long, unsigned long)@CXXABI_1.3.5'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<long long>(long long)@GLIBCXX_3.4.9'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for char*@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_Prime_rehash_policy::_M_need_rehash(unsigned long, unsigned long, unsigned long) const@GLIBCXX_3.4.18'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::out_of_range@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<unsigned long>(unsigned long)@GLIBCXX_3.4.9'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_increment(std::_Rb_tree_node_base const*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::~ios_base()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::range_error::~range_error()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__basic_file<char>::~__basic_file()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_guard_acquire@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<bool>(bool)@GLIBCXX_3.4.9'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::overflow_error@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_fstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::range_error@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ios<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_filebuf<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator delete[](void*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(unsigned long, char, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_transfer(std::__detail::_List_node_base*, std::__detail::_List_node_base*)@GLIBCXX_3.4.15'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::replace(unsigned long, unsigned long, char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for std::exception@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_Rep::_M_destroy(std::allocator<wchar_t> const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream& std::istream::_M_extract<double>(double&)@GLIBCXX_3.4.9'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_fstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::basic_ifstream(char const*, std::_Ios_Openmode)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(std::string const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator new(unsigned long)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_istringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned int@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(char const*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::domain_error@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::find(char, unsigned long) const@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::put(char)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for int@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_bad_alloc()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_thread_atexit@CXXABI_1.3.7'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_increment(std::_Rb_tree_node_base*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::~basic_ifstream()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::Init::Init()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::condition_variable()@GLIBCXX_3.4.11'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::basic_filebuf()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::domain_error::~domain_error()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::cerr@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::find(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::invalid_argument@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for void*@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::assign(std::string const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_rebalance_for_erase(std::_Rb_tree_node_base*, std::_Rb_tree_node_base&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned long@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_hook(std::__detail::_List_node_base*)@GLIBCXX_3.4.15'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_unhook()@GLIBCXX_3.4.15'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ostringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::_M_sync(char*, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_iostream<char, std::char_traits<char> >::~basic_iostream()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_istringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `log2f@GLIBC_2.2.5'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::operator<<(std::basic_streambuf<char, std::char_traits<char> >*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::exception::~exception()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_S_create(unsigned long, unsigned long, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__basic_file<char>::is_open() const@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_istringstream()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::swap(std::string&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned long*@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<char, std::char_traits<char> >::basic_streambuf(std::basic_streambuf<char, std::char_traits<char> > const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::init(std::basic_streambuf<char, std::char_traits<char> >*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_bad_cast()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::clear(std::_Ios_Iostate)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >::operator=(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> > const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator delete(void*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::operator<<(int)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_S_empty_rep_storage@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_M_destroy(std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_iostream<wchar_t, std::char_traits<wchar_t> >::~basic_iostream()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::runtime_error@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ofstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_insert_and_rebalance(bool, std::_Rb_tree_node_base*, std::_Rb_tree_node_base*, std::_Rb_tree_node_base&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_stringstream()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_stringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<long>(long)@GLIBCXX_3.4.9'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream::get()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned long long@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostream<char, std::char_traits<char> >& std::operator<< <std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::out_of_range::~out_of_range()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::length_error::~length_error()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostream<char, std::char_traits<char> >& std::__ostream_insert<char, std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*, long)@GLIBCXX_3.4.9'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::invalid_argument::~invalid_argument()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::swap(std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::cout@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<unsigned long long>(unsigned long long)@GLIBCXX_3.4.9'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for int*@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<void const*>(void const*)@GLIBCXX_3.4.9'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::underflow_error@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_streambuf<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for std::out_of_range@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_allocate_exception@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ios<wchar_t, std::char_traits<wchar_t> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for void const*@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<wchar_t, std::char_traits<wchar_t> >::init(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::reserve(unsigned long)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_begin_catch@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_Rep::_S_empty_rep_storage@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_leak()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::open(char const*, std::_Ios_Openmode)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_M_sync(wchar_t*, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream::getline(char*, long, char)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_istream<char, std::char_traits<char> >& std::getline<char, std::char_traits<char>, std::allocator<char> >(std::basic_istream<char, std::char_traits<char> >&, std::basic_string<char, std::char_traits<char>, std::allocator<char> >&, char)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::~condition_variable()@GLIBCXX_3.4.11'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringbuf<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::insert(unsigned long, char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::assign(char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned char@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::ios_base()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_out_of_range(char const*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::overflow_error::~overflow_error()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_length_error(char const*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_system_error(int)@GLIBCXX_3.4.11'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ofstream<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<double>(double)@GLIBCXX_3.4.9'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<char, std::char_traits<char> >::operator=(std::basic_streambuf<char, std::char_traits<char> > const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long long@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(char const*, unsigned long, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_guard_release@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_throw@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::underflow_error::~underflow_error()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_decrement(std::_Rb_tree_node_base*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::length_error@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::~basic_filebuf()@GLIBCXX_3.4'\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "model = model \n",
    "tokenizer = tokenizer\n",
    "\n",
    "training_dataset = test_dataset\n",
    "\n",
    "trainer = Trainer(model=model, tokenizer=tokenizer, train_dataset=test_dataset, data_collator=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 01:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=51, training_loss=5.488357843137255, metrics={'train_runtime': 97.0708, 'train_samples_per_second': 8.097, 'train_steps_per_second': 0.525, 'total_flos': 506830171078656.0, 'train_loss': 5.488357843137255, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
